{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyPOCQuant user manual\n",
    "\n",
    "## Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "The tool pyPOCQuant aims to automatically detect and quantify signal bands from **Point of Care tests** (**POC** or **POCT**) from an image. It can batch analyze large amounts of images in parallel.\n",
    "\n",
    "An analysis pipeline can be run either from the command line (good for automating large numbers of analysis) or from a desktop application.\n",
    "\n",
    "> At current stage, almost all operations are supported from the user interface, with the exception of the optional [Split images by strip manufacturer](#Split-images-by-POCT-manufacturer) step.\n",
    "\n",
    "![pyPOCQuant user interface](pyPOCQuantUI.png)\n",
    "\n",
    "## Command line workflow <a name=\"command_line_workflow\"></a>\n",
    "\n",
    "1. Split images by POCT manufacturer if needed\n",
    "2. Copy all the images of the same kind into one folder\n",
    "3. Prepare a settings file\n",
    "4. Run the pipeline\n",
    "\n",
    "### Split images by POCT manufacturer\n",
    "\n",
    "> This only applies if you collected many images using POCTs from different vendors and stored all the images in one common folder! Analysis settings would need to be slightly adapted for different POCTs shapes and sizes.\n",
    "\n",
    "If you have many images in an unorganized way we provide a helper script to sort them by manufacturer into subfolders.\n",
    "\n",
    "> This is currently not integrated into the user interface and needs to be run from console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ python ./split_images_by_strip_type_parallel.py -f /PATH/TO/INPUT/FOLDER -o /PATH/TO/OUTPUT/FOLDER -w ${NUM_WORKERS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `/PATH/TO/INPUT/FOLDER`: path to the folder that contains all images for a given camera.\n",
    "\n",
    "* `PATH/TO/OUTPUT/FOLDER`: path where all images will be organized into subfolders; one per each strip manufactured. Strip images that cannot be recognized (or do not contain any strip) will be moved to an ` UNDEFINED` subfolder.\n",
    "\n",
    "  * Currently  recognized manufacturers: \n",
    "    * `AUGURIX`\n",
    "    * `BIOZAK`\n",
    "    * `CTKBIOTECH`\n",
    "    * `DRALBERMEXACARE`\n",
    "    * `LUMIRATEK`\n",
    "    * `NTBIO`\n",
    "    * `SUREBIOTECH`\n",
    "    * `TAMIRNA`\n",
    "\n",
    "**Please notice**: the list of known manufacturers is defined in `pyPOCQuant.consts.KnownManufacturers`.\n",
    "\n",
    "* `NUM_WORKERS`: number of  parallel processes; e.g. `8`.\n",
    "\n",
    "### Settings file preparation <a name=\"settingsprep\"></a>\n",
    "\n",
    "You can prepare a default parameter file from the command line as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ python ./pypocquant/pyPOCQuant_FH.py -c /PATH/TO/INPUT/settings_file.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file in a text editor and edit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_auto_stretch=False\n",
    "raw_auto_wb=False\n",
    "strip_text_to_search='COVID'\n",
    "strip_text_on_right=True\n",
    "strip_size=None\n",
    "qr_code_border=40\n",
    "sensor_size=(61, 249)\n",
    "sensor_center=(178, 667)\n",
    "subtract_background=True\n",
    "sensor_border=(7, 7)\n",
    "perform_sensor_search=True\n",
    "sensor_thresh_factor=2\n",
    "sensor_search_area=(71, 259)\n",
    "peak_expected_relative_location=(0.25, 0.53, 0.79)\n",
    "verbose=True\n",
    "qc=True\n",
    "max_workers=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Some of the parameter names contain the term `strip`: this is used to indicate the POCT. The prefix `sensor` indicates the measurement region within the `strip`.\n",
    "\n",
    "See [Explanations](#Explanations) for detailed description of the parameters.\n",
    "\n",
    "> Please notice that some parameters are considered \"Advanced\"; in the user interface the parameters are separated into \"Runtime parameters\", \"Basic parameters\", and \"Advanced parameters\".\n",
    "\n",
    "#### How to determine the parameters manually <a name=\"settingsprepm\"></a>\n",
    "\n",
    "Open the [settings file](#Settings) and adjust the parameters to fit your images.\n",
    "\n",
    "Important parameters are the `sensor_size`, `sensor_center`, and `sensor_search_area` (the latter being an advanced parameter).\n",
    "\n",
    "> The user interface allows to easily define those parameters by drawing onto the extracted POCT image.\n",
    "\n",
    "Sensor parameters are relative to the POCT image.\n",
    "\n",
    "![Extrated strip](strip_annotated.png)\n",
    "\n",
    "In the following we show how to obtain position and extent of the sensor areas in Fiji. Later we will see how to do the same in the pyPOCQuant user interface.\n",
    "\n",
    "![Area selection in Fiji](fiji_selection.png)\n",
    "\n",
    "* When drawing a rectangular region of interest, the size is displayed in Fiji's toolbar; e.g. `x=539, y=145, **w=230, h=62**`.\n",
    "* When hovering over the central pixels in the top or left sides of the selection, the `x`, and `y` coordinates of the center, respectively, are show in Fiji's toolbar; e.g. `x=*601*, y=144, value=214` (and equivalently for `y`).\n",
    "\n",
    "### Run the pipeline <a name=\"runpipline\"></a>\n",
    "\n",
    "#### Run the analysis per manufacturer manually <a name=\"runpiplinem\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ python pyPOCQuant_FH.py -f /PATH/TO/INPUT/FOLDER/MANUFACTURER -o /PATH/TO/RESULTS/FOLDER -s /PATH/TO/CONFIG/FILE -w ${NUM_WORKERS} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `/PATH/TO/INPUT/FOLDER/MANUFACTURER`: path to the folder that contains all images for a given camera and manufacturer.\n",
    "* `/PATH/TO/RESULTS/FOLDER`: path where the results (and the quality control images) for a given camera and manufacturer will be saved. The results are saved in a `quantification_data.csv` text file.\n",
    "* `/PATH/TO/CONFIG/FILE`: path to the configuration file to be used for this analysis. Please see below. Notice that a configuration file will be needed per manufacturer and (possibly) camera combination.\n",
    "* `NUM_WORKERS`: number of  parallel processes; e.g. `8`.\n",
    "\n",
    "## GUI workflow <a name=\"gui_workflow\"></a>\n",
    "\n",
    "1. Split images by POCT manufacturer if needed\n",
    "2. Copy all the images of the same kind into one folder\n",
    "3. Select the folder containing the images to be processed\n",
    "4. Set all analysis parameters\n",
    "5. Run the pipeline\n",
    "\n",
    "### Split images by POCT manufacturer <a name=\"splitimages_gui\"></a>\n",
    "\n",
    "> This only applies if you collected many images using POCTs from different vendors and stored all the images in one common folder! Analysis settings would need to be slightly adapted for different POCTs shapes and sizes.\n",
    "\n",
    "Please notice that this step has not been integrated into the user interface yet, and must be [run from the command line](#Split-images-by-POCT-manufacturer).\n",
    "\n",
    "#### How to determine the parameters automatically using the GUI <a name=\"settingsprepa\"></a>\n",
    "\n",
    "A settings file must not necessarily be created in advance. The Parameter Tree can be edited directly. Optionally, settings can be loaded or saved from the UI. \n",
    "\n",
    "How to estimate sensor parameters graphically in the UI:\n",
    "\n",
    "* `Select the input folder` and click on one of the listed images to display it. The POCT region will be automatically extracted and shown in the view at the top. The lower view shows the whole image.\n",
    "* Hit the `Draw sensor outline` icon (red arrow) in the toolbar. This will allow you to interactively define the `sensor area and the `peak_expected_relative_location` parameters.\n",
    "\n",
    "![](pyPOCQuantUI_extracting_POCT.png)\n",
    "\n",
    "* Draw the four corners of the sensor and place the vertical bars on the bands. This will cause all relevant parameters to be populated in the Parameter Tree. Please notice that, by default, the `sensor_search_area` is set to be 10 pixels wider and taller than the `sensor_size`. This can be changed in the advanced parameters (but beware to keep it only slightly larger than the `sensor_size`: it is meant only for small refinements).\n",
    "\n",
    "![](pyPOCQuantUI_extracting_sensor_parameters.png)\n",
    "\n",
    "* You can test current parameters on one image by clicking the `Test parameters` button under the Parameter Tree.\n",
    "* Optionally, you can save the settings file (Ctrl+S, `File`->`Save settings file`)\n",
    "\n",
    "#### Run the analysis per manufacturer automatically using the GUI  <a name=\"runpiplinea\"></a>\n",
    "\n",
    "Once the previous steps are done and all parameters are correctly set, you can hit the `Run` button to start the analysis.\n",
    "\n",
    "## Settings\n",
    "\n",
    "The following settings must be specified. These are default values and need to be adopted for a series of the same kind of images. Please note: in the following, `strip` is used to indicate the POCT, and `sensor` to indicate the measurement region within the `strip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_auto_stretch=False\n",
    "raw_auto_wb=False\n",
    "strip_text_to_search=\"COVID\"\n",
    "strip_text_on_right=True\n",
    "min_sensor_score=0.85\n",
    "qr_code_border=40\n",
    "sensor_size=(62, 230)\n",
    "sensor_center=(152, 601)\n",
    "subtract_background=True\n",
    "sensor_border_x=7\n",
    "sensor_border_y=7\n",
    "perform_sensor_search=True\n",
    "sensor_thresh_factor=2\n",
    "sensor_search_area=(71, 259)\n",
    "peak_expected_relative_location=(0.25, 0.53, 0.79)\n",
    "verbose=True\n",
    "qc=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanations\n",
    "\n",
    "#### Runtime parameters\n",
    "\n",
    "##### Number of cores\n",
    "\n",
    "* The analysis can work in parallel. Specify the maximum number of images that are run in parallel. The maximum allowed value is the number of cores in your machine.\n",
    "\n",
    "##### qc\n",
    "\n",
    "* Toggle creation of quality control images.\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `True` when testing parameters.\n",
    "\n",
    "##### verbose\n",
    "\n",
    "* Toggle extensive information logging.\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `True` when testing parameters.\n",
    "\n",
    "#### Basic parameters\n",
    "\n",
    "##### sensor_size\n",
    "\n",
    "* Area in pixels of the sensor to be extracted: `(height, width)`.\n",
    "\n",
    "##### sensor_center\n",
    "\n",
    "*  Coordinates in pixels of the center of the sensor with respect to the strip image: `(y, x)`.\n",
    "\n",
    "##### sensor_border_x\n",
    "\n",
    "* Lateral sensor border in pixels to be ignored in the analysis to avoid border effects.\n",
    "\n",
    "##### sensor_border_y\n",
    "\n",
    "* Vertical sensor border in pixels to be ignored in the analysis to avoid border effects.\n",
    "\n",
    "##### subtract_background\n",
    "\n",
    "* If `True`, estimate and subtract the background of the sensor intensity profile (bands).\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `True`\n",
    "\n",
    "##### perform_sensor_search\n",
    "\n",
    "* If `True`, the (inverted) sensor is searched within `sensor_search_area` around the expected `sensor_center`; if `False`, the sensor of size `sensor_size` is simply extracted from the strip image centered at the relative strip position `sensor_center`.\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `True`\n",
    "\n",
    "##### peak_expected_relative_location\n",
    "\n",
    "* Expected relative peak positions as a function of the width of the sensor (= 1.0).\n",
    "\n",
    "| POCT            | peak_expected_relative_location |\n",
    "| --------------- | ------------------------------- |\n",
    "| AUGURIX         | (0.30, 0.50, 0.70)              |\n",
    "| BIOZAK          | (0.25, 0.50, 0.75)              |\n",
    "| CTKBIOTECH      | (0.25, 0.53, 0.79)              |\n",
    "| SUREBIOTECH     | (0.31, 0.54, 0.75)              |\n",
    "| TARMINA         | -                               |\n",
    "| DRALBERMEXACARE | -                               |\n",
    "| LUMIRATEK       | -                               |\n",
    "| NTBIO           | -                               |\n",
    "\n",
    "  **Some pre-calculated `peak_expected_relative_location` values for known POCTs.**\n",
    "\n",
    "##### qr_code_border\n",
    "\n",
    "* Lateral and vertical extension of the (white) border around each QR code.\n",
    "\n",
    "##### strip_text_to_search\n",
    "\n",
    "* Text to search on the strip to assess orientation. Set to `\"\"` to skip. This can help if the automatic estimation of the strip orientation fails. If the strip has some text printed on either side of the sensor, it can be searched to guess the orientation. See also `strip_text_on_right`.\n",
    "\n",
    "##### strip_text_on_right\n",
    "* Assuming the strip is oriented horizontally, whether the `strip_text_to_search` text\n",
    "    is expected to be on the right. If `strip_text_on_right` is `True` and the text is found on the\n",
    "    left hand-side of the strip, the strip will be rotated 180 degrees.\n",
    "* Ignored if `strip_text_to_search` is `\"\"`.\n",
    "\n",
    "#### Advanced parameters\n",
    "\n",
    "These parameters will most likely work with the default values above.\n",
    "\n",
    "##### sensor_search_area\n",
    "\n",
    "* Search area in pixels around the sensor: `(height, width)`. \n",
    "* Used only if `skip_sensor_search` is `False`.\n",
    "* **Try to keep it just a bit larger than the sensor size: in particular, try to avoid picking up features (e.g. text) in close proximity of the sensor.**\n",
    "\n",
    "##### sensor_thresh_factor\n",
    "\n",
    "* Set the number of (robust) standard deviations away from the median band background for a peak (band)\n",
    "      to be considered valid.\n",
    "* Recommended: `2`, maybe `3`.\n",
    "\n",
    "##### raw_auto_stretch\n",
    "\n",
    "* Whether to automatically correct the white balance of RAW images on load. This does not affect JPEG images!\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `False`\n",
    "\n",
    "##### raw_auto_wb\n",
    "\n",
    "* Whether to automatically stretch image intensities of RAW images on load. This does not affect JPEG images!\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `False`\n",
    "\n",
    "## Results <a name=\"resultsdescription\"></a>\n",
    "\n",
    "The analysis pipeline delivers a `.csv` that contains a relatively large table of results. The extracted features are explained in the following.\n",
    "\n",
    "### Result table <a name=\"resulttable\"></a>\n",
    "\n",
    "Structure and description of the result table:\n",
    "\n",
    "* `fid`: patient FID in the form `F5921788`\n",
    "* `fid_num`: just the numeric part of the FID (i.e., `5921788`)\n",
    "* `filename`: name of the analyzed image\n",
    "* `extension`: extension (either *.JPG or *.NEF)\n",
    "* `basename`: filename without extension\n",
    "* `iso_date`: date of image acquisition in the form YYYY-MM-DD (e.g. 2020-04-14)\n",
    "* `iso_time`: time of image acquisition in the form HH-MM-SS (24-h format)\n",
    "* `exp_time`: camera exposure time\n",
    "* `f_number`: aperture F number\n",
    "* `focal_length_35_mm`: 35mm equivalent focal length\n",
    "* `iso_speed`: camera ISO value\n",
    "* `manufacturer`:  POCT manufacturer\n",
    "* `plate`: plate number\n",
    "* `well`: well (e.g. `A 01`)\n",
    "* `ctl`: 1 if the control band could be extracted, 0 otherwise.\n",
    "* `igm`: 1 if the IgM band could be extracted, 0 otherwise.\n",
    "* `igg`: 1 if the IgG band could be extracted, 0 otherwise. \n",
    "* `ctl_abs`: absolute signal strength of the control band,\n",
    "* `igm_abs`: absolute signal strength of the IgM band,\n",
    "* `igg_abs`: absolute signal strength of the IgG band.\n",
    "* `ctl_ratio`: relative signal strength of the control band (always 1.0 if detected)\n",
    "* `igm_ratio`: relative signal strength of the IgM band with respect to the control band\n",
    "* `igg_ratio`: relative signal strength of the IgG band with respect to the control band\n",
    "* `issue`: if issue is 0, the image could be analyzed successfully, if issue > 0 it could not. See the list of issues below\n",
    "* `user`: custom field\n",
    "\n",
    "> Note: expect small residual variations in the absolute signal strengths (`ctl_abs`, `igm_abs`, and `igg_abs`) across images in a batch due to inhomogeneities  in acquisition.\n",
    "\n",
    "#### Analysis issues<a name=\"analysisissues\"></a>\n",
    "\n",
    "Each analyzed image is assigned an integer `issue`:\n",
    "\n",
    "* 0: no issue, the analysis could be performed successfully\n",
    "\n",
    "* 1: barcode extraction failed\n",
    "\n",
    "* 2: FID extraction failed\n",
    "\n",
    "* 3: poor strip alignment (see `strip_corr_coeff` column in the results data table)\n",
    "\n",
    "* 4: sensor extraction failed (see `sensor_score` column in the results data table)\n",
    "\n",
    "* 5: peak/band quantification failed\n",
    "\n",
    "* 6: control band missing\n",
    "\n",
    "### Quality control images <a name=\"resultimages\"></a>\n",
    "\n",
    "Types and examples' of quality control images:\n",
    "\n",
    "Raw image here just shown as comparison:\n",
    "<img src=\"IMG_8489.png\" style=\"zoom:35%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `IMAGE_FILE_NAME_aligned_box` Aligned raw image\n",
    "<img src=\"IMG_8489_JPG_aligned_box.png\" style=\"zoom:35%;\" />\n",
    "* `IMAGE_FILE_NAME_box` : QR code box around the POCT oriented such that the control band is always on the right side.\n",
    "<img src=\"IMG_8489_JPG_box.png\" style=\"zoom:35%;\" />\n",
    "\n",
    "* `IMAGE_FILE_NAME_rotated`: Raw image rotated such that the POCT is at the parallel to the bottom side of the image.\n",
    "<img src=\"IMG_8489_JPG_rotated.png\" style=\"zoom:35%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `IMAGE_FILE_NAME_strip_gray_aligned`: Aligned POCT cropped around its outline such that it is parallel to the bottom side.\n",
    "<img src=\"IMG_8489_JPG_strip_gray_aligned.png\" style=\"zoom:35%;\" />\n",
    "\n",
    "* `IMAGE_FILE_NAME_strip_gray_aligned_after_ocr` Aligned POCT cropped around its outline such that it is parallel to the bottom side after OCR filtering such that the pipetting part is always left (for the cases where the POCT was not placed in the correct orientation in the template.)\n",
    "<img src=\"IMG_8489_JPG_strip_gray_aligned_after_ocr.png\" style=\"zoom:35%;\" />\n",
    "\n",
    "* `IMAGE_FILE_NAME_strip_gray_hough_analysis.png` Aligned POCT cropped around its outline such that it is parallel to the bottom side detecting the pipetting spot to identify wrongly oriented POCT in the strip box. The rectangles indicate the search areas while as the circles indicate potential hits for the pipetting spot. Red rectangle and magenta circles identifies the side where the pipetting spot was detected. Note it is assumed that the control band is always opposite of the pipetting area.\n",
    "<img src=\"IMG_8489_JPG_strip_gray_hough_analysis.png\" style=\"zoom:35%;\" />\n",
    "\n",
    "* `IMAGE_FILE_NAME_sensor`: Aligned sensor crop showing the bands.\n",
    "<img src=\"IMG_8489_JPG_sensor.png\" style=\"zoom:100%;\" />\n",
    "\n",
    "* `IMAGE_FILE_NAME_peak_overlays`: Sensor crop with colored rectangle overlay(s) indicating the area(s) where the signal for each detected band is quantified. Notice that the rectangle extends to cover the whole area under the curve, from background level through peak and back to background level.\n",
    "<img src=\"IMG_8489_JPG_peak_overlays.png\" style=\"zoom:50%;\" />\n",
    "\n",
    "* `IMAGE_FILE_NAME_peak_background_estimation`: Control figure displaying the performance of the background estimation fit. Black dashed line is a an estimation of the background level obtained by robust linear fit of the band profile. From the estimate background trend a constant value is subtracted (resulting red solid line). This is to make sure that the signal is flat after correction, but no values are clipped.\n",
    "<img src=\"IMG_8489_JPG_peak_background_estimation.png\" style=\"zoom:45%;\" />\n",
    "\n",
    "* `IMAGE_FILE_NAME_peak_analysis`: Control figure displaying the performance of the peak analysis. Red circle indicates the max peak height. The green dashed line is an estimate of the local background that is used to test all candidate local maxima against a threshold defined by the red dashed line. This line is calculated as the (median of the background values) + `f` * (median deviation of the background values). The factor `f`    is a user parameter and defaults to 2. The solid blue, orange and green line under the curves indicate the local span of each of the bands and indicate which part of the signal is integrated.\n",
    "<img src=\"IMG_8489_JPG_peak_analysis.png\" style=\"zoom:45%;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log file <a name=\"resultlog\"></a>\n",
    "\n",
    "The log file contains more detailed information for each processed image identified by its file name such as `Img0052.jpg`. \n",
    "\n",
    "It informs about the barcode extraction and its rotation, the QR code box rotation, the FID extraction, the actual sensor coordinates and the identified bands.\n",
    "\n",
    "Example log:\n",
    "\n",
    "```\n",
    "File = IMG_8489.JPG\n",
    "Processing IMG_8489.JPG\n",
    "Best percentiles for barcode extraction: (0, 100); best scaling factor = 0.25; score = 6/6\n",
    "File IMG_8489.JPG: best percentiles for barcode extraction after rotation: (0, 100); best scaling factor = 0.25; score = 6/6\n",
    "File IMG_8489.JPG: Strip box image rotated by angle -0.9172186022623166 degrees using QR code locations.\n",
    "File IMG_8489.JPG: FID = 'F5923994'\n",
    "File IMG_8489.JPG: sensor coordinates = [140, 207, 523, 780], score = 1.0\n",
    "Peak 69 has lower bound 48 (d = 21) with relative intensity 0.06 and upper bound 93 (d = 24) with relative intensity 0.00. Band width is 46. Band skewness is 1.14\n",
    "Peak 138 has lower bound 104 (d = 34) with relative intensity 0.00 and upper bound 162 (d = 24) with relative intensity 0.10. Band width is 59. Band skewness is 0.71\n",
    "Peak 203 has lower bound 170 (d = 33) with relative intensity 0.04 and upper bound 248 (d = 45) with relative intensity 0.00. Band width is 79. Band skewness is 1.36\n",
    "File IMG_8489.JPG: the bands were 'normal'.\n",
    "âœ“ File IMG_8489.JPG: successfully processed and added to results table.\n",
    "```\n",
    "\n",
    "### Settings file <a name=\"resultsettings\"></a>\n",
    "\n",
    " A settings file is created in the `-o /PATH/TO/RESULTS/FOLDER` with the actually used parameters for the analysis. It can be used to reproduce the obtained results.\n",
    "\n",
    "See [settings file section](#Settings) for detailed description.\n",
    "\n",
    "## Graphical user interface <a name=\"gui\"></a>\n",
    "\n",
    "The GUI offers several actions via the menu, the toolbar and buttons.\n",
    "\n",
    "![](pyPOCQuantUI.png)\n",
    "\n",
    "1. `File menu`:\n",
    "\n",
    "   * `File`: Lets you load ( `File` $\\rightarrow$ `Load settings file`) and save ( `File` $\\rightarrow$ `Save settings file`) a settings file\n",
    "\n",
    "   * `Help`: Get quick instructions and open this manual\n",
    "   \n",
    "2. `Toolbar`:\n",
    "   * `Load settings from file`: Load settings from file into the Parameter Tree.\n",
    "   * ``Save settings to file`: Save current settings to file.\n",
    "\t* `Draw sensor outline`: Activates drawing a polygon by clicking into the corners of the sensor on the images.\n",
    "\t* `Delete sensor`: Deletes currently drawn sensor.\n",
    "\t* `Mirror image vertically`: Mirrors the displayed image vertically.\n",
    "\t* `Mirror image horizontally`: Mirrors the displayed image horizontally.\n",
    "\t* `Rotate clockwise`: Rotates the displayed image clock wise.\n",
    "\t* `Rotate counter clockwise`: Rotates the displayed image counter clock wise.\n",
    "\t* `Set rotation angle in degrees`: Specifies the rotation angle.\n",
    "\t* `Zoom in`: Zooms in  the displayed image.\n",
    "\t* `Zoom out`: Zooms out  the displayed image .\n",
    "\t* `Reset zoom`: Resets the zoom level.\n",
    "\t* `Show / hide console`: shows or hides the console at the bottom of the UI.\n",
    "\t\n",
    "3. ``Select input folder`: Allows to specify the input folder.\n",
    "\n",
    "   `Select output folder`: (Optional) Lets you select a output folder. If left empty a output subfolder is automatically generated  in the input folder.\n",
    "\n",
    "   `Image list`: Lists all available images in the input folder. Click onto the filename to display one in **5**\n",
    "\n",
    "4. `Parameter Tree`: Adjust parameters manually if needed.\n",
    "\n",
    "5. `POCT area`: Shows the extracted POCT and allows for drawing the sensor.\n",
    "\n",
    "6. `Display area`: Shows the currently selected image.\n",
    "\n",
    "7. `Test parameters`: Runs the pipeline on the selected image with current settings. The test folder will be opened automatically to inspect the control files.\n",
    "\n",
    "8. `Run`: Runs the pipeline with the current settings**.\n",
    "\n",
    "9. `Log`: Information the user about performed actions.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "bash",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
