{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyPOCQuant user manual\n",
    "\n",
    "## Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "The tool __pyPOCQuant__ aims to automatically detect and quantify signal bands from __lateral flow assays__ (__LFA__) or **Point of Care tests** (**POC** or **POCT**) from an image. It can batch analyze large amounts of images in parallel.\n",
    "\n",
    "An analysis pipeline can be run either from the command line (good for automating large numbers of analysis) or from a desktop application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ui_images/ui_full_empty.JPG\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command line workflow <a name=\"command_line_workflow\"></a>\n",
    "\n",
    "1. Split images by POCT manufacturer if needed\n",
    "2. Copy all the images of the same kind into one folder\n",
    "3. Prepare a settings (configuration) file\n",
    "4. Run the pipeline\n",
    "\n",
    "### Split images by POCT manufacturer\n",
    "\n",
    "> This only applies if you collected many images using POCTs from different vendors and stored all the images in one common folder! Analysis settings would need to be slightly adapted for different POCTs shapes and sizes.\n",
    "\n",
    "If you have many images in an unorganized way we provide a helper script to sort them by manufacturer into subfolders.\n",
    "\n",
    "> This can also be run from the UI, see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ python ./split_images_by_strip_type_parallel.py -f /PATH/TO/INPUT/FOLDER -o /PATH/TO/OUTPUT/FOLDER -w ${NUM_WORKERS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `/PATH/TO/INPUT/FOLDER`: path to the folder that contains all images for a given camera.\n",
    "\n",
    "* `PATH/TO/OUTPUT/FOLDER`: path where all images will be organized into subfolders; one per each strip manufactured. Strip images that cannot be recognized (or do not contain any strip) will be moved to an ` UNDEFINED` subfolder.\n",
    "\n",
    "  * Currently  recognized manufacturers: \n",
    "    * `AUGURIX`\n",
    "    * `BIOZAK`\n",
    "    * `CTKBIOTECH`\n",
    "    * `DRALBERMEXACARE`\n",
    "    * `LUMIRATEK`\n",
    "    * `NTBIO`\n",
    "    * `SUREBIOTECH`\n",
    "    * `TAMIRNA`\n",
    "\n",
    "**Please notice**: the list of known manufacturers is defined in `pyPOCQuant.consts.KnownManufacturers`.\n",
    "\n",
    "* `NUM_WORKERS`: number of  parallel processes; e.g. `8`.\n",
    "\n",
    "### Settings file preparation <a name=\"settingsprep\"></a>\n",
    "\n",
    "You can prepare a default parameter file from the command line as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ python ./pypocquant/pyPOCQuant_FH.py -c /PATH/TO/INPUT/settings_file.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file in a text editor and edit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc=True\n",
    "verbose=True\n",
    "sensor_band_names=('igm', 'igg', 'ctl')\n",
    "peak_expected_relative_location=(0.25, 0.53, 0.79)\n",
    "sensor_center=(178, 667)\n",
    "sensor_size=(61, 249)\n",
    "sensor_border=(7, 7)\n",
    "perform_sensor_search=True\n",
    "qr_code_border=40\n",
    "subtract_background=True\n",
    "sensor_search_area=(71, 259)\n",
    "sensor_thresh_factor=2.0\n",
    "raw_auto_stretch=False\n",
    "raw_auto_wb=False\n",
    "strip_try_correct_orientation=False\n",
    "strip_try_correct_orientation_rects=(0.52, 0.15, 0.09)\n",
    "strip_text_to_search='COVID'\n",
    "strip_text_on_right=True\n",
    "force_fid_search=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Some of the parameter names contain the term `strip`: this is used to indicate the POCT. The prefix `sensor` indicates the measurement region within the `strip`.\n",
    "\n",
    "See [Explanations](#Explanations) for detailed description of the parameters.\n",
    "\n",
    "> Please notice that some parameters are considered \"Advanced\"; in the user interface the parameters are separated into \"Runtime parameters\", \"Basic parameters\", and \"Advanced parameters\".\n",
    "\n",
    "#### How to determine the parameters manually <a name=\"settingsprepm\"></a>\n",
    "\n",
    "Open the [settings file](#Settings) and adjust the parameters to fit your images.\n",
    "\n",
    "Important parameters are the `sensor_size`, `sensor_center`, and `sensor_search_area` (the latter being an advanced parameter).\n",
    "\n",
    "> The user interface allows to easily define those parameters by drawing onto the extracted POCT image.\n",
    "\n",
    "Sensor parameters are relative to the POCT image.\n",
    "\n",
    "<img src=\"demo_image/strip_annotated.png\"/>\n",
    "\n",
    "In the following we show how to obtain position and extent of the sensor areas in Fiji or ImageJ. Later we will see how to do the same in the pyPOCQuant user interface.\n",
    "\n",
    "<img src=\"demo_image/fiji_selection.png\"/>\n",
    "\n",
    "* When drawing a rectangular region of interest, the size is displayed in Fiji's toolbar; e.g. `x=539, y=145, **w=230, h=62**`.\n",
    "* When hovering over the central pixels in the top or left sides of the selection, the `x`, and `y` coordinates of the center, respectively, are show in Fiji's toolbar; e.g. `x=*601*, y=144, value=214` (and equivalently for `y`).\n",
    "\n",
    "### Run the pipeline <a name=\"runpipline\"></a>\n",
    "\n",
    "#### Run the analysis per manufacturer manually <a name=\"runpiplinem\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ python pyPOCQuant_FH.py -f /PATH/TO/INPUT/FOLDER/MANUFACTURER -o /PATH/TO/RESULTS/FOLDER -s /PATH/TO/CONFIG/FILE -w ${NUM_WORKERS} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `/PATH/TO/INPUT/FOLDER/MANUFACTURER`: path to the folder that contains all images for a given camera and manufacturer.\n",
    "\n",
    "* `/PATH/TO/RESULTS/FOLDER`: path where the results (and the quality control images) for a given camera and manufacturer will be saved. The results are saved in a `quantification_data.csv` text file.\n",
    "\n",
    "* `/PATH/TO/CONFIG/FILE`: path to the configuration file to be used for this analysis. Please see below. Notice that a configuration file will be needed per manufacturer and (possibly) camera combination.\n",
    "\n",
    "* `NUM_WORKERS`: number of  parallel processes; e.g. `8`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI workflow <a name=\"gui_workflow\"></a>\n",
    "\n",
    "1. Split images by POCT manufacturer if needed\n",
    "2. Copy all the images of the same kind into one folder\n",
    "3. Select the folder containing the images to be processed\n",
    "4. Set all analysis parameters\n",
    "5. Run the pipeline\n",
    "\n",
    "### Split images by POCT manufacturer <a name=\"splitimages_gui\"></a>\n",
    "\n",
    "> This only applies if you collected many images using POCTs from different vendors and stored all the images in one common folder! Analysis settings would need to be slightly adapted for different POCTs shapes and sizes.\n",
    "\n",
    "To do so go to `File` --> `Split images by type` to open the dialog to split the images.\n",
    "\n",
    "#### How to determine the parameters automatically using the GUI <a name=\"settingsprepa\"></a>\n",
    "\n",
    "A settings file must not necessarily be created in advance. The Parameter Tree can be edited directly. Optionally, settings can be loaded or saved from the UI. \n",
    "\n",
    "How to estimate sensor parameters graphically in the UI:\n",
    "\n",
    "* `Select the input folder` and click on one of the listed images to display it. The POCT region will be automatically extracted and shown in the view at the top. Please mind that this can take a few seconds. The lower view shows the whole image.\n",
    "\n",
    "* Hit the `Draw sensor outline` icon (red arrow) in the toolbar. This will allow you to interactively define the `sensor area` and the `peak_expected_relative_location` parameters.\n",
    "\n",
    "| Drawing sensor by clicking into the corners | Drawing finished with aligned bars      |\n",
    "| ------------------------------------------- | ----------------------------------------- |\n",
    "| <img src=\"ui_images/ui_drawing_arrow.JPG\"/> | <img src=\"ui_images/ui_bar_aligned.JPG\"/> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Draw the four corners of the sensor and place the vertical bars on the bands. This will cause all relevant parameters to be populated in the Parameter Tree. Please notice that, by default, the `sensor_search_area` is set to be 10 pixels wider and taller than the `sensor_size`. This can be changed in the advanced parameters (but beware to keep it only slightly larger than the `sensor_size`: it is meant only for small refinements).\n",
    "\n",
    "<img src=\"ui_images/ui_new_settings.JPG\"/>\n",
    "\n",
    "* You can test current parameters on one image by clicking the `Test parameters` button under the Parameter Tree.\n",
    "* Optionally, you can save the settings file (Ctrl+S, `File`->`Save settings file`)\n",
    "\n",
    "#### Run the analysis per manufacturer automatically using the GUI  <a name=\"runpiplinea\"></a>\n",
    "\n",
    "Once the previous steps are done and all parameters are correctly set, you can hit the `Run` button to start the analysis.\n",
    "\n",
    "_Note: a step by step guide can be found under **Quick start** (`Help -> Quick start`)_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "The following settings must be specified. These are default values and need to be adopted for a series of the same kind of images. Please note: in the following, `strip` is used to indicate the POCT, and `sensor` to indicate the measurement region within the `strip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc=True\n",
    "verbose=True\n",
    "sensor_band_names=('igm', 'igg', 'ctl')\n",
    "peak_expected_relative_location=(0.25, 0.53, 0.79)\n",
    "sensor_center=(178, 667)\n",
    "sensor_size=(61, 249)\n",
    "sensor_border=(7, 7)\n",
    "perform_sensor_search=True\n",
    "qr_code_border=40\n",
    "subtract_background=True\n",
    "sensor_search_area=(71, 259)\n",
    "sensor_thresh_factor=2.0\n",
    "raw_auto_stretch=False\n",
    "raw_auto_wb=False\n",
    "strip_try_correct_orientation=False\n",
    "strip_try_correct_orientation_rects=(0.52, 0.15, 0.09)\n",
    "strip_text_to_search='COVID'\n",
    "strip_text_on_right=True\n",
    "force_fid_search=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanations\n",
    "\n",
    "#### Runtime parameters\n",
    "\n",
    "<img src=\"ui_images/runtime_params.JPG\"/>\n",
    "\n",
    "##### max_workers\n",
    "\n",
    "* The analysis can work in parallel. Specify the maximum number of images that are run in parallel. The maximum allowed value is the number of cores in your machine.\n",
    "\n",
    "##### qc\n",
    "\n",
    "* Toggle creation of quality control images.\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `True` when testing parameters.\n",
    "\n",
    "##### verbose\n",
    "\n",
    "* Toggle extensive information logging.\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `True` when testing parameters.\n",
    "\n",
    "#### Basic parameters\n",
    "\n",
    "<img src=\"ui_images/basic_params.JPG\"/>\n",
    "\n",
    "##### number_of_sensor_bands\n",
    "\n",
    "* It defines the number of test lines (TLs) to be expected in the POCT, including the control line. This parameter is used by the user interface to dynamically adapt the tree for related settings (see `sensor_band_names` and `peak_expected_relative_location` below), and is not part of the settings file, since it can be easily derived fro those parameters.\n",
    "* Possible values: `2` to `100`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### control_band_index\n",
    "* Index of the control line.\n",
    "* Possible values: `0`, `1`, `...`, `number_of_sensor_bands - 1`; or `-1` (last index).\n",
    "* Default: `-1` (in Python parlance, `-1` means last index, or, the first index from the right).\n",
    "\n",
    "##### sensor_band_names\n",
    "\n",
    "* Custom name for the test lines (by default 3, needs to match the number of defined TLs `number_of_sensor_bands`) `t2`, `t1` and `ctl` (e.g., `IgM`, `IgG` and `Ctl`).\n",
    "\n",
    "##### peak_expected_relative_location\n",
    "\n",
    "* Expected relative peak positions as a function of the width of the sensor (= 1.0). These values can easily be set interactively [using the UI](#settingsprepa).\n",
    "\n",
    "##### sensor_center\n",
    "\n",
    "*  Coordinates in pixels of the center of the sensor with respect to the strip image: `(y, x)`.\n",
    "\n",
    "##### sensor_size\n",
    "\n",
    "* Area in pixels of the sensor to be extracted: `(height, width)`.\n",
    "\n",
    "##### sensor_border\n",
    "\n",
    "* Lateral and vertical sensor border in pixels to be ignored in the analysis to avoid border effects: `(lateral, vertical)`.\n",
    "\n",
    "##### perform_sensor_search\n",
    "\n",
    "* If `True`, the (inverted) sensor is searched within `sensor_search_area` around the expected `sensor_center`; if `False`, the sensor of size `sensor_size` is simply extracted from the strip image centered at the relative strip position `sensor_center`.\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `True`\n",
    "\n",
    "##### qr_code_border\n",
    "\n",
    "* Lateral and vertical extension of the (white) border around each QR code.\n",
    "\n",
    "##### subtract_background\n",
    "\n",
    "* If `True`, estimate and subtract the background of the sensor intensity profile (bands).\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `True`\n",
    "\n",
    "#### Advanced parameters\n",
    "\n",
    "These parameters will most likely work with the default values above.\n",
    "\n",
    "<img src=\"ui_images/advanced_params.JPG\"/>\n",
    "\n",
    "##### sensor_search_area\n",
    "\n",
    "* Search area in pixels around the sensor: `(height, width)`. \n",
    "* Used only if `skip_sensor_search` is `False`.\n",
    "* **Try to keep it just a bit larger than the sensor size: in particular, try to avoid picking up features (e.g. text) in close proximity of the sensor.**\n",
    "\n",
    "##### sensor_thresh_factor\n",
    "\n",
    "* Set the number of (robust) standard deviations away from the median band background for a peak (band) to be considered valid.\n",
    "* Recommended: `2`, maybe `3`.\n",
    "\n",
    "##### raw_auto_stretch\n",
    "\n",
    "* Whether to automatically correct the white balance of RAW images on load. This does not affect JPEG images!\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `False`\n",
    "\n",
    "##### raw_auto_wb\n",
    "\n",
    "* Whether to automatically stretch image intensities of RAW images on load. This does not affect JPEG images!\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `False`\n",
    "\n",
    "##### strip_try_correct_orientation\n",
    "\n",
    "* Whether to automatically try to rotate a POCT that was mistakenly placed on the template facing the wrong direction (and where the control band is on the left instead of on the right). The pipetting inlet will be searched in the POCT; the inlet is assumed to be found on the side opposite to the control band, and always on the left. If found on the right, the image will be rotated.\n",
    "* Possible values: `True` or `False`\n",
    "* Default: `False` \n",
    "* If set to `True`, make sure to properly set the `strip_try_correct_orientation_rects` parameters below!\n",
    "\n",
    "##### strip_try_correct_orientation_rects\n",
    "\n",
    "* Parameters for defining two rectangles left and right from the sensor center to be used to detect the pipetting inlet. The first parameter, `Relative height factor`, defines the relative height of the rectangles with respect to the strip. The second parameter, `Relative center cut-off`, defines the relative offset from the sensor center and therefore the width of the rectangle. Finally, the third parameter, `Relative border cut-off`, defines the relative offset from the strip's left and right borders and hence the width of the search rectangle.\n",
    "* Possible values: `(0:1, 0:1, 0:1)`\n",
    "* Default: `(0.52, 0.15, 0.09)`\n",
    "\n",
    "##### strip_text_to_search\n",
    "\n",
    "* Whether to use a specific text printed on the POCT to automatically try to rotate a POCT that was mistakenly placed on the template facing the wrong direction (and where the control band is on the left instead of on the right). Set to `\"\"` to skip search and correction. If the strip has some text printed on either side of the sensor, it can be searched to guess the orientation. See also `strip_text_on_right`.\n",
    "\n",
    "##### strip_text_on_right\n",
    "\n",
    "* Assuming the strip is oriented horizontally, whether the `strip_text_to_search` text is expected to be on the right. If `strip_text_on_right` is `True` and the text is found on the left hand-side of the strip, the strip will be rotated 180 degrees.\n",
    "* Ignored if `strip_text_to_search` is `\"\"`.\n",
    "\n",
    "##### force_fid_search\n",
    "\n",
    "* If force fid search is activated, try hard (and slow!) to find an FID on a barcode or QR code label on the image identifying the sample.\n",
    "* Possible values: `True` or `False`\n",
    "* Recommended: `False`\n",
    "\n",
    "## Results <a name=\"resultsdescription\"></a>\n",
    "\n",
    "The analysis pipeline delivers a `.csv` that contains a relatively large table of results. The extracted features are explained in the following.\n",
    "\n",
    "### Result table <a name=\"resulttable\"></a>\n",
    "\n",
    "Structure and description of the result table:\n",
    "\n",
    "`fid`: patient FID in the form `F5921788`\n",
    "\n",
    "`fid_num`: just the numeric part of the FID (i.e., `5921788`)\n",
    "\n",
    "`filename`: name of the analyzed image\n",
    "\n",
    "`extension`: extension (either *.JPG or *.ARW, *.CR2, *.NEF)\n",
    "\n",
    "`basename`: filename without extension\n",
    "\n",
    "`iso_date`: date of image acquisition in the form YYYY-MM-DD (e.g. 2020-04-14)\n",
    "\n",
    "`iso_time`: time of image acquisition in the form HH-MM-SS (24-h format)\n",
    "\n",
    "`exp_time`: camera exposure time\n",
    "\n",
    "`f_number`: aperture F number\n",
    "\n",
    "`focal_length_35_mm`: 35mm equivalent focal length\n",
    "\n",
    "`iso_speed`: camera ISO value\n",
    "\n",
    "`manufacturer`:  POCT manufacturer\n",
    "\n",
    "`plate`: plate number\n",
    "\n",
    "`well`: well (e.g. `A 01`)\n",
    "\n",
    "`ctl`: 1 if the control band could be extracted, 0 otherwise.\n",
    "\n",
    "`t2`: 1 if the `t2` band (e.g. IgM) could be extracted, 0 otherwise.\n",
    "\n",
    "`t1`: 1 if the `t1` band (e.g. IgG) could be extracted, 0 otherwise. \n",
    "\n",
    "`ctl_abs`: absolute signal strength of the control band,\n",
    "\n",
    "`t2_abs`: absolute signal strength of the `t2` band,\n",
    "\n",
    "`t1_abs`: absolute signal strength of the `t1` band.\n",
    "\n",
    "`ctl_ratio`: relative signal strength of the control band (always 1.0 if detected)\n",
    "\n",
    "`t2_ratio`: relative signal strength of the `t2` band with respect to the control band\n",
    "\n",
    "`t1_ratio`: relative signal strength of the `t1` band with respect to the control band\n",
    "\n",
    "`issue`: if issue is 0, the image could be analyzed successfully, if issue > 0 it could not. See the list of issues below\n",
    "\n",
    "`user`: custom field\n",
    "\n",
    "> Note: expect small residual variations in the absolute signal strengths (`ctl_abs`, `t2_abs`, and `t1_abs`) across images in a batch due to inhomogeneities  in acquisition.\n",
    "\n",
    "> None 2: `ctl`, `t1`, and `t2` in the column names will be replaced by the names defines in `sensor_band_names`. For examples, `t1_ratio` may  become `igg_ratio`.\n",
    "\n",
    "> Note 3: The number of test lines (TL) changes according to the parameter `number_of_sensor_bands`. By default, 3 TLs are defined including the `ctl` line. Changing the number of TLs also changes the number of columns in the results table.\n",
    "\n",
    "#### Analysis issues<a name=\"analysisissues\"></a>\n",
    "\n",
    "Each analyzed image is assigned an integer `issue`:\n",
    "\n",
    "* 0: no issue, the analysis could be performed successfully\n",
    "* 1: barcode extraction failed\n",
    "* 2: FID extraction failed\n",
    "* 3: strip box extraction failed\n",
    "* 4: strip extraction failed\n",
    "* 5: poor strip alignment\n",
    "* 6: sensor extraction failed\n",
    "* 7: peak/band quantification failed\n",
    "* 8: control band missing\n",
    "\n",
    "### Quality control images <a name=\"resultimages\"></a>\n",
    "\n",
    "Types and examples' of quality control images:\n",
    "\n",
    "Raw image shown as comparison:\n",
    "\n",
    "<img src=\"demo_image/IMG_8489.png\" style=\"zoom:35%;\" />\n",
    "\n",
    "* `IMAGE_FILE_NAME_aligned_box` Aligned raw image\n",
    "\n",
    "  <img src=\"demo_image/IMG_8489_JPG_aligned_box.jpg\" style=\"zoom:5%;\" />\n",
    "\n",
    "* `IMAGE_FILE_NAME_box` : QR code box around the POCT oriented such that the control band is always on the right side.\n",
    "\n",
    "  <img src=\"demo_image/IMG_8489_JPG_box.jpg\" style=\"zoom:20%;\" />\n",
    "\n",
    "* `IMAGE_FILE_NAME_rotated`: Raw image rotated such that the POCT is at the parallel to the bottom side of the image.\n",
    "\n",
    "  <img src=\"demo_image/IMG_8489_JPG_rotated.jpg\" style=\"zoom:5%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `IMAGE_FILE_NAME_strip_gray_aligned`: Aligned POCT cropped around its outline such that it is parallel to the bottom side.\n",
    "\n",
    "  <img src=\"demo_image/IMG_8489_JPG_strip_gray_aligned.png\" style=\"zoom:30%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `IMAGE_FILE_NAME_strip_gray_aligned_after_ocr` Aligned POCT cropped around its outline such that it is parallel to the bottom side after OCR filtering such that the pipetting part is always left (for the cases where the POCT was not placed in the correct orientation in the template.)\n",
    "\n",
    "  <img src=\"demo_image/IMG_8489_JPG_strip_gray_aligned_after_ocr3.png\" style=\"zoom:30%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `IMAGE_FILE_NAME_strip_gray_hough_analysis` Aligned POCT cropped around its outline such that it is parallel to the bottom side detecting the pipetting spot to identify wrongly oriented POCT in the strip box. \n",
    "\n",
    "  <img src=\"demo_image/IMG_8489_JPG_strip_gray_hough_analysis.png\" style=\"zoom:30%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `IMAGE_FILE_NAME_strip_gray_hough_analysis_candidates` Hough analysis candidate results. The rectangles indicate the search areas while as the circles indicate potential hits for the pipetting spot. Red rectangle and magenta circles identifies the side where the pipetting spot was detected. Note it is assumed that the control band is always opposite of the pipetting area.\n",
    "\n",
    "  <img src=\"demo_image/IMG_8489_JPG_strip_gray_hough_analysis_candidates.png\" style=\"zoom:30%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `IMAGE_FILE_NAME_sensor`: Aligned sensor crop showing the bands.\n",
    "\n",
    "  <img src=\"demo_image/IMG_8489_JPG_sensor.png\" style=\"zoom:100%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `IMAGE_FILE_NAME_peak_overlays`: Sensor crop with colored rectangle overlay(s) indicating the area(s) where the signal for each detected band is quantified. Notice that the rectangle extends to cover the whole area under the curve, from background level through peak and back to background level.\n",
    "\n",
    "  <img src=\"demo_image/IMG_8489_JPG_peak_overlays.png\" style=\"zoom:50%;\" />\n",
    "\n",
    "* `IMAGE_FILE_NAME_peak_background_estimation`: Control figure displaying the performance of the background estimation fit. Black dashed line is a an estimation of the background level obtained by robust linear fit of the band profile. From the estimate background trend a constant value is subtracted (resulting red solid line). This is to make sure that the signal is flat after correction, but no values are clipped.\n",
    "\n",
    "  <img src=\"demo_image/IMG_8489_JPG_peak_background_estimation.png\" style=\"zoom:45%;\" />\n",
    "\n",
    "* `IMAGE_FILE_NAME_peak_analysis`: Control figure displaying the performance of the peak analysis. Red circle indicates the max peak height. The green dashed line is an estimate of the local background that is used to test all candidate local maxima against a threshold defined by the red dashed line. This line is calculated as the (median of the background values) + `f` * (median deviation of the background values). The factor `f`   is a user parameter and defaults to 2. The solid blue, orange and green line under the curves indicate the local span of each of the bands and indicate which part of the signal is integrated.\n",
    "\n",
    "  <img src=\"demo_image/IMG_8489_JPG_peak_analysis.png\" style=\"zoom:45%;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log file <a name=\"resultlog\"></a>\n",
    "\n",
    "The log file contains more detailed information for each processed image identified by its file name, such as `IMG_8489.JPG`. \n",
    "\n",
    "It informs about barcode extraction and its rotation, QR code box rotation, FID extraction, actual sensor coordinates and the identified bands.\n",
    "\n",
    "Example log:\n",
    "\n",
    "```\n",
    "File = IMG_8489.JPG\n",
    "Processing IMG_8489.JPG\n",
    "Best percentiles for barcode extraction: (0, 100); best scaling factor = 0.25; score = 6/6\n",
    "File IMG_8489.JPG: best percentiles for barcode extraction after rotation: (0, 100); best scaling factor = 0.25; score = 6/6\n",
    "File IMG_8489.JPG: Strip box image rotated by angle -0.9172186022623166 degrees using QR code locations.\n",
    "File IMG_8489.JPG: FID = 'F5923994'\n",
    "File IMG_8489.JPG: sensor coordinates = [140, 207, 523, 780], score = 1.0\n",
    "Peak 69 has lower bound 48 (d = 21) with relative intensity 0.06 and upper bound 93 (d = 24) with relative intensity 0.00. Band width is 46. Band skewness is 1.14\n",
    "Peak 138 has lower bound 104 (d = 34) with relative intensity 0.00 and upper bound 162 (d = 24) with relative intensity 0.10. Band width is 59. Band skewness is 0.71\n",
    "Peak 203 has lower bound 170 (d = 33) with relative intensity 0.04 and upper bound 248 (d = 45) with relative intensity 0.00. Band width is 79. Band skewness is 1.36\n",
    "File IMG_8489.JPG: the bands were 'normal'.\n",
    "✓ File IMG_8489.JPG: successfully processed and added to results table.\n",
    "```\n",
    "\n",
    "### Settings file <a name=\"resultsettings\"></a>\n",
    "\n",
    "A settings file is created in the `-o /PATH/TO/RESULTS/FOLDER` with the actually used parameters for the analysis. It can be used to reproduce the obtained results.\n",
    "\n",
    "See [settings file section](#Settings) for detailed description.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical user interface <a name=\"gui\"></a>\n",
    "\n",
    "The GUI offers several actions via the menu, the toolbar and buttons.\n",
    "\n",
    "<img src=\"ui_images/pyPOCQuantMain-01.PNG\"/>\n",
    "\n",
    "1. `File menu`:\n",
    "\n",
    "   <img src=\"ui_images/file.JPG\"/>\n",
    "\n",
    "   * `File`: Lets you load ( `File` --> `Load settings file`) and save ( `File` --> `Save settings file`) a settings file\n",
    "   \n",
    "   * `Help`: Get quick instructions and open this manual\n",
    "   \n",
    "2. `Toolbar`:\n",
    "\n",
    "   <img src=\"ui_images/toolbar.JPG\"/>\n",
    "\n",
    "   * `Load settings from file`: Load settings from file into the Parameter Tree.\n",
    "   * `Save settings to file`: Save current settings to file.\n",
    "   * `Draw sensor outline`: Activates drawing a polygon by clicking into the corners of the sensor on the images.\n",
    "   * `Delete sensor`: Deletes currently drawn sensor.\n",
    "   * `Mirror image vertically`: Mirrors the displayed image vertically.\n",
    "   * `Mirror image horizontally`: Mirrors the displayed image horizontally.\n",
    "   * `Rotate clockwise`: Rotates the displayed image clock wise.\n",
    "   * `Rotate counter clockwise`: Rotates the displayed image counter clock wise.\n",
    "   * `Set rotation angle in degrees`: Specifies the rotation angle.\n",
    "   * `Zoom in`: Zooms in  the displayed image.\n",
    "   * `Zoom out`: Zooms out  the displayed image .\n",
    "   * `Reset zoom`: Resets the zoom level.\n",
    "   * `Measure distance`: Lets you draw a line on the image to measure distances. It will update the `qr_border_distance` parameter.\n",
    "   * `Show / hide console`: shows or hides the console at the bottom of the UI.\n",
    "\n",
    "3. `Select input folder`: Allows to specify the input folder.\n",
    "\n",
    "   `Select output folder`: (Optional) Lets you select a output folder. If left empty a output subfolder is automatically generated  in the input folder.\n",
    "\n",
    "   `Image list`: Lists all available images in the input folder. Click onto the filename to display one in **5**.\n",
    "\n",
    "4. `Parameter Tree`: Adjust parameters manually if needed.\n",
    "\n",
    "5. `POCT area`: Shows the extracted POCT and allows for drawing the sensor.\n",
    "\n",
    "6. `Display area`: Shows the currently selected image.\n",
    "\n",
    "7. `Test parameters`: Runs the pipeline on the selected image with current settings. The test folder will be opened automatically to inspect the control files.\n",
    "\n",
    "8. `Run`: Runs the pipeline with the current settings**.\n",
    "\n",
    "10. `Log`: Informs the user about performed actions.\n",
    "\n",
    "11. `Tools menu`:\n",
    "\n",
    "    <img src=\"ui_images/tools.JPG\"/>\n",
    "\n",
    "    * `Save POCT template`: Lets you save and print the POCT template to be used for the image acquisition.\n",
    "\n",
    "    * `Save QR labels template` Lets you save an Excel template to be used to generate QR code labels for all your samples from a list.\n",
    "\n",
    "    * `Generate QR labels`: Lets you generate QR labels for your samples using the excel template or a csv file with a list of the names in the correct format: `SAMPEID-MANUFACTURER-PLATE-WELL-USERDATA`. You can use the `USERDATA` field for **very short** annotations; please make sure not to use dashes (`-`) in this field, but replace them with underscores (`_`). You can define the page size, label size, position and number per page to match the format for any printable label paper as, for instance, from AVERY.\n",
    "\n",
    "      <img src=\"ui_images/generate_labels.JPG\"/>\n",
    "\n",
    " * `Split images by type`: helps organizing mixtures of images from different POCT manufacturers stored in one and the same folder. The tool will analyze each of the images and attempt to extract the manufacturer information from the QR code (if present) or by searching for the name on the POCT itself (OCR). If the manufacturer can be resolved, the image is moved into a sub-folder with the name of the manufacturer, otherwise it will be moved into a subfolder called UNDEFINED. As long as the QR code structure is satisfied (which is guaranteed if using the `Generate QR labels` tool explained above), even previously unknown manufacturers can be recognized. Should the QR code detection fail, a fall-back OCR detection can use a comma-separated list of expected manufacturer names to potentially identify unknown manufacturers. The `input folder` defines the folder containing all the images to process, and `output folder` the location where the split images should be moved. The `number of cores` defines the number of images that will be processed in parallel. \n",
    "\n",
    "      <img src=\"ui_images/tool_split_images.JPG\"/>\n",
    "\n",
    "12. `Help menu`:\n",
    "\n",
    "    <img src=\"ui_images/help.JPG\"/>\n",
    "\n",
    "    * `Quick instructions`: Shows the quick instructions dialog.\n",
    "\n",
    "    * `Quick start`: Opens the quick start document describing how to set up the image acquisition setup, perform the acquisition and some potential problems and their solutions one might encounter.\n",
    "\n",
    "    * `User manual`: Opens this document.\n",
    "\n",
    "    * `About`: About the software and its dependencies.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "bash",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
